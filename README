Write a short description of how the Lexer works in compiler design and the files that were generated when you ran you lexer.
 The lexer is a program that perform Lexical Analysis in compiler design. The lexer takes the modified source code which is in the form of sentences. In this project, I created tokens for "char", "write", "return", ";", ",", ", "=", and {NUMBER}. For instance, if you put the word "return" each respectively, r,e,t,u,r,and n are meaningless. However, "return" becomes meaningful through tokenization. When this token steps through the lexer, it analyzes the meaning and returns the "return" word. This token is analyzed like {type: , value: "return", child:[]} and transfers to the Parser. As I explain, other tokens that I made also step through lexer to analyze and return it.

Describe the tokens you will need to build a full language (this will be project 2). Make sure to describe theoretical principles, design practices, and implementation strategies of compiler design that you will put into practice.
 
For the new tokens I will need to add different keywords to the language to be able to identify what type of which function they will preform in the language that we are creating. I will be doing this by using the same method that I did for making the return token. 
